# Problem Set 02: Marketing y Anal√≠tica del Retail
**Mag√≠ster in Business Analytics and Data Science - UDP**

Este repositorio contiene la resoluci√≥n del Problem Set 02, enfocado en el procesamiento de datos no estructurados y sistemas de recomendaci√≥n aplicados al retail. El proyecto aborda desaf√≠os reales como el ruido en los datos, la dispersi√≥n (sparsity) y la evaluaci√≥n de modelos de lenguaje.

## üìã √çndice
1. [Parte 1: NLP y Embeddings](#parte-1-nlp-y-embeddings)
2. [Parte 2: Modelado de T√≥picos (BERTopic)](#parte-2-modelado-de-t√≥picos)
3. [Parte 3: Recomendaci√≥n (Feedback Expl√≠cito)](#parte-3-recomendaci√≥n-expl√≠cita)
4. [Parte 4: Recomendaci√≥n (Feedback Impl√≠cito)](#parte-4-recomendaci√≥n-impl√≠cita)
5. [Requisitos T√©cnicos](#requisitos-t√©cnicos)

---

## üß† Parte 1: NLP y Embeddings
Utilizando el dataset `retail_reviews.csv`, se explor√≥ la representaci√≥n vectorial del lenguaje y la clasificaci√≥n de sentimientos.

### 1.1. An√°lisis Sem√°ntico (Word2Vec)
Se entren√≥ un modelo para identificar t√©rminos similares. Resultados obtenidos:
* **T√©rminos similares a "r√°pido":** *recomendado, excelente, eficaz, entrega, puntual.*
* **Similitud:** Se observaron puntajes de similitud superiores al **0.98**, validando que el modelo captura correctamente el contexto de eficiencia log√≠stica.
* **Interpretaci√≥n Matem√°tica:** Se utiliza la **Similitud Coseno** porque mide el √°ngulo entre vectores, ignorando su magnitud. Esto es cr√≠tico en retail, ya que palabras frecuentes (magnitud alta) no necesariamente son m√°s relevantes sem√°nticamente que palabras t√©cnicas menos frecuentes.

### 1.2. Clasificaci√≥n con Transformers (BERT vs Baseline)
Se compar√≥ el rendimiento de clasificaci√≥n binaria (Sentimiento Positivo/Negativo):
* **TF-IDF + Logistic Regression:** F1-Score de **0.9000**
* **BERT Embeddings + Logistic Regression:** F1-Score de **0.8924**
> **Nota:** Aunque TF-IDF tuvo un puntaje ligeramente superior, BERT demostr√≥ mayor capacidad para entender rese√±as con sarcasmo o ambig√ºedad estructural.

---

## üìä Parte 2: Modelado de T√≥picos (BERTopic)
Se implement√≥ **BERTopic** para descubrir temas latentes en las rese√±as de los clientes sin supervisi√≥n previa.

* **T√≥picos Identificados:** * **T√≥pico 0:** Satisfacci√≥n general y buen empaque (ej. "lleg√≥", "bien", "empaquetado").
    * **T√≥pico 7:** Problemas con empaques defectuosos o sucios.
    * **T√≥pico 11:** Experiencias negativas con atenci√≥n al cliente.
* **Visualizaci√≥n:** Se generaron mapas de distancia inter-t√≥pica para analizar la jerarqu√≠a de los comentarios mediante UMAP y HDBSCAN.



---

## üé¨ Parte 3: Recomendaci√≥n (Feedback Expl√≠cito)
An√°lisis del dataset `video_ratings.csv` para la predicci√≥n de valoraciones (1-5 estrellas).

* **Enfoque:** Filtrado Colaborativo basado en modelos.
* **Desaf√≠o:** El sistema maneja una **Sparsity Extrema** (20,000 registros para una matriz de 600 usuarios y 150 pel√≠culas), optimizando la predicci√≥n de ratings para usuarios con pocos datos hist√≥ricos.

---

## üéµ Parte 4: Recomendaci√≥n (Feedback Impl√≠cito)
An√°lisis de comportamiento mediante `music_logs.csv`, utilizando el conteo de reproducciones (`play_count`) como se√±al de inter√©s.

* **M√©trica de Evaluaci√≥n:** Implementaci√≥n de **NDCG@K** (Normalized Discounted Cumulative Gain).
* **Ejemplo de Resultado:** Para un ranking de 5 canciones donde los aciertos est√°n en las posiciones 1, 3 y 4, el modelo calcula:
    * **DCG@5:** $\sum_{i=1}^{5} \frac{rel_i}{\log_2(i + 1)}$
    * **Resultado:** Permite penalizar si las canciones favoritas del usuario aparecen al final de la lista recomendada.



---

## üõ†Ô∏è Requisitos T√©cnicos
Para ejecutar el notebook `Tarea2_v1.ipynb`, aseg√∫rese de contar con el siguiente entorno:

### Dependencias Principales
```bash
pip install tensorflow==2.16.2 tf_keras transformers sentence-transformers gensim scikit-learn bertopic plotly